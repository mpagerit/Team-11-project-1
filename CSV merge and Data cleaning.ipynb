{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicole's code starts here \n",
    "# Importing \"The Numbers\" data & cleaning it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import OMB_api_key\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_df = pd.read_csv('DataFiles/TheNumbers_Original.csv')\n",
    "print(numbers_df.shape)\n",
    "numbers_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create month released column & add to dataframe. Probably don't need to do this since we can\n",
    "# return the month after turning it into a datetime data type\n",
    "numbers_df['Domestic Release Date'] = numbers_df['Domestic Release Date'].astype('datetime64[ns]')\n",
    "numbers_df['Worldwide Release Date'] = numbers_df['Worldwide Release Date'].astype('datetime64[ns]')\n",
    "month = pd.DatetimeIndex(numbers_df['Domestic Release Date']).month\n",
    "numbers_df.insert(3, 'Month Released (Domestic)', month)\n",
    "numbers_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns 11 + to integer\n",
    "numbers_df[numbers_df.columns[11:]] = numbers_df[numbers_df.columns[11:]].apply\\\n",
    "(lambda x: x.str.replace('$','')).apply(lambda x: x.str.replace(',','')).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding available oscar count per year. Somebody please check these calculations if we use this!\n",
    "numbers_df['Total Oscars Awarded in Year'] = ''\n",
    "for index, row in numbers_df.iterrows():\n",
    "    year = row['Year Released (Domestic)']\n",
    "    if year == 1980:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 22\n",
    "    elif year in range(1981,1995) or year == 1999:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 23\n",
    "    elif year in range(2001,2020):\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 25\n",
    "    else:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title needs cleaning (remove apostrophes, colons, eplipses, \"Ep. xxx:\")\n",
    "# The order it is replaced is sequential (ie: relacing Ep. I, followd by Ep. II returns I)\n",
    "\n",
    "# Creating new title column so we can use original title later\n",
    "numbers_df.insert(6, 'Query_Title', numbers_df['Title'])\n",
    "\n",
    "# Replacing characters\n",
    "numbers_df[numbers_df.columns[6:7]] = numbers_df[numbers_df.columns[6:7]].apply\\\n",
    "(lambda x: x.str.replace(\":\",'')).apply(lambda x: x.str.replace(\"Ep.\",\"Episode\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit movies to 40 per year - defined as top 40 by adjusted gross ***\n",
    "numbers_df = numbers_df.sort_values(['Year Released (Domestic)', 'Infl. Adj. Dom. Box Office'],\n",
    "                                    ascending = [True, False])\n",
    "numbers_df = numbers_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still limiting...\n",
    "numbers_df['Year Index'] = ''\n",
    "year_compare = 1980\n",
    "count = 0\n",
    "for index, row in numbers_df.iterrows():\n",
    "    year = row['Year Released (Domestic)']\n",
    "    if year == year_compare:\n",
    "        count += 1\n",
    "        numbers_df.loc[index, 'Year Index'] = count\n",
    "    else:\n",
    "        count = 1\n",
    "        numbers_df.loc[index, 'Year Index'] = count\n",
    "        year_compare += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... a little more & voila!\n",
    "top_40_df = numbers_df.loc[(numbers_df['Year Index'] <=40), ['Title', 'Query_Title',\n",
    "                                                             'Domestic Release Date',\n",
    "                                                             'Year Released (Domestic)',\n",
    "                                                             'Month Released (Domestic)',\n",
    "                                                             'Infl. Adj. Dom. Box Office',\n",
    "                                                             'Domestic Box Office',\n",
    "                                                             'Genre', 'Theatrical Distributor',\n",
    "                                                             'Total Oscars Awarded in Year']]\n",
    "top_40_df = top_40_df.sort_values('Infl. Adj. Dom. Box Office', ascending = False)\n",
    "top_40_df = top_40_df.reset_index(drop = True)\n",
    "top_40_df.to_csv('DataFiles/TheNumbers_Cleaned.csv')\n",
    "print(top_40_df.shape)\n",
    "top_40_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********  This is the end of data_cleaning & start of request tests ***********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to hold subset request data\n",
    "omdb_df = top_40_df.copy()\n",
    "omdb_df['Awards'] = ''\n",
    "omdb_df['Metascore'] = ''\n",
    "omdb_df['IMDB'] = ''\n",
    "omdb_df['Rotten Tomatoes'] = ''\n",
    "omdb_df['Rated'] = ''\n",
    "omdb_df['Director'] = ''\n",
    "omdb_df['Runtime'] = ''\n",
    "omdb_df['Country'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** The following cells are just for testing and can eventually be removed from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Sample JSON in case you want to run one specific movie title\n",
    "movie_title = \"The battle of the five armies\"\n",
    "params = {'type': 'movie', 'apikey': OMB_api_key, 't': movie_title}\n",
    "url = 'http://www.omdbapi.com/?t='\n",
    "response = requests.get(url, params).json()\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Sample JSON in case you want to run one specific movie title\n",
    "movie_title = \"Epic\"\n",
    "year = 2013\n",
    "params = {'type': 'movie', 'apikey': OMB_api_key, 't': movie_title, 'y': year}\n",
    "url = 'http://www.omdbapi.com/?t='\n",
    "response = requests.get(url, params).json()\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Subset dataframe for request testing\n",
    "test_subset = omdb_df.iloc[25:39, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Testing Requests on subset.\n",
    "# If one of the values within a found movie is missing, it stops inputting data into DF after that\n",
    "#     and I told it to print that so we know (uncomment the metascore row to view this)\n",
    "# If we find a lot of missing movies, we could look into adding a year parameter.\n",
    "#     It looks like it returns the first movie found (ie: 'Star Wars' returns 'Star Wars IV')\n",
    "\n",
    "params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "url = \"http://www.omdbapi.com/?t=\"\n",
    "count = 0\n",
    "for index, row in test_subset.iterrows():\n",
    "    params[\"t\"] = row[\"Query_Title\"]\n",
    "    response = requests.get(url, params).json()\n",
    "    if response['Response'] == 'True':\n",
    "        try:\n",
    "            omdb_df.loc[index, 'Awards'] = response['Awards']\n",
    "            omdb_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "            omdb_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "            omdb_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "            omdb_df.loc[index, 'Rated'] = response['Rated']\n",
    "            omdb_df.loc[index, 'Director'] = response['Director']\n",
    "            omdb_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "            omdb_df.loc[index, 'Country'] = response['Country']\n",
    "        except:\n",
    "            print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "        count += 1\n",
    "    else:\n",
    "        print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** API requests All Data *****\n",
    "\n",
    "# params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# count = 0\n",
    "# for index, row in omdb_df.iterrows():\n",
    "#     params['t'] = row[\"Query_Title\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             omdb_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             omdb_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             omdb_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             omdb_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             omdb_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             omdb_df.loc[index, 'Director'] = response['Director']\n",
    "#             omdb_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             omdb_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(omdb_df.shape)\n",
    "# omdb_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving what we have so far\n",
    "# omdb_df.to_csv('DataFiles/First_API_Run_BETA.csv', index=False)\n",
    "\n",
    "# Loading for demo purposes\n",
    "omdb_df = pd.read_csv('DataFiles/First_API_Run_BETA.csv')\n",
    "omdb_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicole's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jason's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 files one for data already populated (clean_test_df) for John to work with Analysis\n",
    "# the second is for Marianne and I to parse through and find on OMDB\n",
    "clean_test_df = omdb_df.dropna()\n",
    "# clean_test_df.head(50)\n",
    "# clean_test_df.to_csv('DataFiles/clean_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_cleaned_df = omdb_df[pd.isnull(omdb_df['Awards'])]\n",
    "to_be_cleaned_df.head()\n",
    "to_be_cleaned_df.shape\n",
    "# to_be_cleaned_df.to_csv('DataFiles/to_be_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_clean_data = pd.read_csv('DataFiles/to_be_clean_data.csv')\n",
    "to_be_clean_data\n",
    "jason_cleanup_df= to_be_clean_data.head(75)\n",
    "jason_cleanup_df\n",
    "#create a new dataframe with the movies that actually need cleaning\n",
    "# j_cleaning_df = jason_cleanup_df[pd.isnull(jason_cleanup_df['Metascore'])&pd.isnull(jason_cleanup_df['IMDB'])]\n",
    "# j_cleaning_df\n",
    "# j_cleaning_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_cleaning_df.at[[10],'Query_Title'] = \"The battle of the five armies\"\n",
    "j_cleaning_df\n",
    "\n",
    "j_cleaning_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out lines that were mistakenly included into the nan dataset based on awards stats\n",
    "# and save for re-merging later \n",
    "j_clean_awards_df = jason_cleanup_df.dropna(subset=['IMDB']) #'Metascore']), 'IMDB'])\n",
    "j_clean_awards_df\n",
    "j_clean_awards_df.shape\n",
    "\n",
    "# jason_cleanup_df.to_csv('DataFiles/jason_cleanup_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = j_cleaning_df.append(j_clean_awards_df, ignore_index=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('DataFiles/jason_cleanup_done_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jason's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marianne's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marianne's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEPS\n",
    "# Pull out NaN values from omdb_df and resave\n",
    "# Create new dataframes with only NaN values & figure out how to make successful API calls on them\n",
    "    # (might be a series of datframes & API calls after tweaking key words or maybe adding variable for year)\n",
    "# Pull out oscar nominations and wins\n",
    "# Save & review final dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
